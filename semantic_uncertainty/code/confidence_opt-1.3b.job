#!/bin/bash
#SBATCH --job-name=clean_string_opt_1.3b
#SBATCH --output=/home/bhsshah/llm-uncertainty-project/semantic_uncertainty/logs/confidence_opt_1.3b_out.txt
#SBATCH --error=/home/bhsshah/llm-uncertainty-project/semantic_uncertainty/logs/confidence_opt_1.3b_err.txt
#SBATCH --time=02-00:00
#SBATCH --mem=32000
#SBATCH --gres=gpu:1

echo "===== Job started on $(hostname) ====="
echo "Date: $(date)"

# Ensure script runs from project code directory
cd ~/llm-uncertainty-project/semantic_uncertainty/code

# Activate your conda environment (update name if needed)
source ~/miniconda3/etc/profile.d/conda.sh
conda activate semantic_uncertainty
echo "===== NVIDIA-SMI ====="
nvidia-smi

python3 -c "
import wandb
from dotenv import load_dotenv
load_dotenv()
run_id = wandb.util.generate_id()
wandb.init(project='nlg_uncertainty_opt_350m', id=run_id)
print(run_id)
"
run_id="run_1"
echo "This is the run id $(run_id)"
model='opt-1.3b'
python3 compute_confidence_measure.py --evaluation_model=$model --generation_model=$model --run_id=$run_id --project=$model --dataset="trivia_qa"
echo "===== Job finished ====="
